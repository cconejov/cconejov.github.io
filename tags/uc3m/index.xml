<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>UC3M | Academic</title>
    <link>https://cconejov.github.io/tags/uc3m/</link>
      <atom:link href="https://cconejov.github.io/tags/uc3m/index.xml" rel="self" type="application/rss+xml" />
    <description>UC3M</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Tue, 21 Sep 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>UC3M</title>
      <link>https://cconejov.github.io/tags/uc3m/</link>
    </image>
    
    <item>
      <title>Master&#39;s thesis: Application of Convolutional networks in the Multiple Hypothesis Testing</title>
      <link>https://cconejov.github.io/project/uc3m_master_thesis/</link>
      <pubDate>Tue, 21 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://cconejov.github.io/project/uc3m_master_thesis/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Multiple Hypothesis testing consists of a series of statistical procedures for solving hypothesis tests on high-dimensional data marginally.  Several approaches have been developed for dealing with this statistical problem. Classical methods consist of defining and controlling a specific error rate. These methods usually rely on the p-values for collecting the evidence against the null hypothesis. Other alternatives have also been developed under a semi-supervised approach. In this case, we solve the large-scale testing using a null train sampling collected via endogenous or exogenous mechanisms.  In this project, we combine both approaches. Employing simulations, we explore the possibility of handling cases where the user knows and controls the ground truth for solving multiple hypothesis testing problems in a supervised framework. Starting with calibrated p-values under the null hypothesis, we represent the p-values in terms of odds, converting them into lower bounds of Bayes Factors.
Additionally, we take a step further, creating a matrix of the relative evidence among tests as the previously ordered minimum bounds quotients. This matrix representation is considered analogous to an image. With these ingredients, we train Convolutional Neural Networks to determine if this framework can detect the cases where the null hypothesis is rejected. We explore the ability of the CNNs to correctly classifying the hypothesis based on two primary examples. First, we study the efficiency of a diet applied to a female mice sample under several scenarios. Then, we explore the mean difference of two independent populations sampling from the normal distribution.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
